# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bqD17R1MgtlAyd0DEvjRLEDvpkEE7WZp
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit sentence-transformers pandas faiss-cpu plotly

# app.py - Final Tabbed Streamlit app with multilingual search, charts, chat and client-side voice capture + TTS
import streamlit as st
import pickle, numpy as np, faiss, os
import pandas as pd
from sentence_transformers import SentenceTransformer
import plotly.express as px
import streamlit.components.v1 as components

# -----------------------------
# Config & Load resources
# -----------------------------
st.set_page_config(page_title="SkillMap AI â€” NCO Semantic Search", layout="wide")

@st.cache_resource
def load_resources():
    # Files expected in same folder:
    # nco_df.pkl, scheme_df.pkl, nco_embeddings.npy, scheme_embeddings.npy, nco_faiss.index
    df_jobs = pickle.load(open("nco_df.pkl", "rb"))
    df_schemes = pickle.load(open("scheme_df.pkl", "rb"))
    job_embeddings = np.load("nco_embeddings.npy")
    scheme_embeddings = np.load("scheme_embeddings.npy")
    index = faiss.read_index("nco_faiss.index")
    # multilingual model for queries & scheme embeddings
    model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
    return df_jobs, df_schemes, job_embeddings, scheme_embeddings, index, model

if not (os.path.exists("nco_df.pkl") and os.path.exists("nco_faiss.index")):
    st.error("Missing data files. Upload nco_df.pkl, scheme_df.pkl, nco_embeddings.npy, scheme_embeddings.npy, nco_faiss.index into app folder.")
    st.stop()

df_jobs, df_schemes, job_embeddings, scheme_embeddings, index, model = load_resources()

# compute sector from nco_code's first digit if not present
def infer_sector_from_code(code):
    if pd.isna(code): return "Unknown"
    first = str(code).strip().split('.')[0]
    if len(first) >= 1:
        digit = first[0]
        # simple mapping example (you can refine)
        mapping = {
            '0': 'Elementary occupations',
            '1': 'Managers/Professionals',
            '2': 'Professionals',
            '3': 'Technicians',
            '4': 'Clerical',
            '5': 'Service/Sales',
            '6': 'Skilled Agricultural',
            '7': 'Craft & Trade',
            '8': 'Plant/Machine Operators',
            '9': 'Other'
        }
        return mapping.get(digit, "Other")
    return "Unknown"

if 'sector' not in df_jobs.columns:
    df_jobs['sector'] = df_jobs['nco_code'].apply(infer_sector_from_code)

# -----------------------------
# Styling (background + card)
# -----------------------------
page_bg = """
<style>
.stApp {
  background: linear-gradient(90deg, rgba(245,249,255,1) 0%, rgba(235,244,252,1) 50%, rgba(245,249,255,1) 100%);
}
.result-card {
  background: rgba(255,255,255,0.92);
  padding: 12px;
  border-radius: 12px;
  box-shadow: 0 6px 18px rgba(20,20,20,0.06);
  margin-bottom: 12px;
}
.small-muted { color: #6c757d; font-size: 13px;}
</style>
"""
st.markdown(page_bg, unsafe_allow_html=True)

# -----------------------------
# Utility functions
# -----------------------------
def semantic_search_jobs(query, top_k=5):
    q_emb = model.encode([query], convert_to_numpy=True)
    faiss.normalize_L2(q_emb)
    D, I = index.search(q_emb, top_k)
    results = df_jobs.iloc[I[0]].copy()
    results['similarity'] = D[0]
    return results

def recommend_schemes_for_text(text, top_k=3):
    job_emb = model.encode([text], convert_to_numpy=True)[0]
    # cosine similarity with precomputed scheme_embeddings
    scores = (scheme_embeddings @ job_emb) / (np.linalg.norm(scheme_embeddings, axis=1) * np.linalg.norm(job_emb))
    idx = np.argsort(scores)[::-1][:top_k]
    res = df_schemes.iloc[idx].copy()
    res['similarity'] = scores[idx]
    return res

# Browser TTS function via a tiny HTML/JS component
def browser_tts(text, lang='en-US'):
    # Use JS speechSynthesis to speak the text
    escaped = text.replace("'", "\\'").replace("\n"," ")
    js = f"""
    <script>
    const msg = new SpeechSynthesisUtterance('{escaped}');
    msg.lang = '{lang}';
    window.speechSynthesis.cancel(); // stop previous
    window.speechSynthesis.speak(msg);
    </script>
    """
    components.html(js, height=0)

# Voice recorder component (client-side) - returns recognized text inside the component UI (user copies into search box)
VOICE_COMPONENT = """
<div style="font-family:sans-serif;">
  <button id="startBtn" style="padding:8px 12px;border-radius:6px;background:#0b6efd;color:white;border:none;cursor:pointer;">ðŸŽ¤ Start Voice Capture</button>
  <button id="stopBtn" style="padding:8px 12px;border-radius:6px;background:#6c757d;color:white;border:none;cursor:pointer;margin-left:8px;">â–  Stop</button>
  <div style="margin-top:8px;">
    <b>Recognized text (copy -> paste to search box):</b>
    <div id="out" style="margin-top:6px;padding:8px;border-radius:6px;background:#fff;min-height:40px;border:1px solid #ddd;"></div>
  </div>
  <div style="margin-top:8px;">
    <button id="copyBtn" style="padding:6px 10px;border-radius:6px;background:#0b6efd;color:white;border:none;cursor:pointer;">Copy to clipboard</button>
  </div>
</div>
<script>
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const out = document.getElementById('out');
const copyBtn = document.getElementById('copyBtn');

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (!SpeechRecognition) {
  out.innerText = 'Voice recognition not supported in this browser. Use Chrome or Edge.';
  startBtn.disabled = true;
  stopBtn.disabled = true;
} else {
  const rec = new SpeechRecognition();
  rec.lang = 'en-IN'; // default; user can speak other langs too
  rec.interimResults = true;
  rec.continuous = true;
  let finalTranscript = '';
  rec.onresult = (event) => {
    let interim = '';
    for (let i = event.resultIndex; i < event.results.length; ++i) {
      if (event.results[i].isFinal) {
        finalTranscript += event.results[i][0].transcript;
      } else {
        interim += event.results[i][0].transcript;
      }
    }
    out.innerText = (finalTranscript + ' ' + interim).trim();
  };
  rec.onerror = (e) => { out.innerText = 'Error: ' + e.error; };
  startBtn.onclick = () => { finalTranscript = ''; out.innerText = ''; rec.start(); startBtn.disabled = true; stopBtn.disabled = false; };
  stopBtn.onclick = () => { rec.stop(); startBtn.disabled = false; stopBtn.disabled = true; };
  copyBtn.onclick = async () => {
    const text = out.innerText;
    try {
      await navigator.clipboard.writeText(text);
      copyBtn.innerText = 'Copied!';
      setTimeout(()=>copyBtn.innerText='Copy to clipboard',1500);
    } catch(e) {
      copyBtn.innerText = 'Press Ctrl+C to copy';
    }
  };
}
</script>
"""

# -----------------------------
# Layout: Tabs
# -----------------------------
tabs = st.tabs(["ðŸ”Ž Search", "ðŸ“Š Charts", "ðŸ’¬ Chat & Voice"])

# -----------------------------
# Tab 1: Search
# -----------------------------
with tabs[0]:
    st.header("NCO Semantic Search & Scheme Recommender")
    col1, col2 = st.columns([3,1])
    with col1:
        query = st.text_input("Enter job / skill (type or paste voice text):", "")
        top_k = st.slider("Number of job matches", 1, 10, 5)
        search_btn = st.button("Search")
    with col2:
        st.markdown("**Voice Input**")
        # Render VOICE_COMPONENT in a fixed height container
        components.html(VOICE_COMPONENT, height=200)

    if search_btn and query.strip():
        with st.spinner("Searching..."):
            # multilingual embedding model will handle many languages
            query_text = query.strip()
            jobs = semantic_search_jobs(query_text, top_k=top_k)
        st.success(f"Top {len(jobs)} matches for: \"{query_text}\"")
        all_result_rows = []
        for i, row in jobs.iterrows():
            st.markdown(f"<div class='result-card'>", unsafe_allow_html=True)
            st.markdown(f"**[{row['nco_code']}] {row['title']}**  <span class='small-muted'>&nbsp;&nbsp;Score: {row['similarity']:.3f}</span>", unsafe_allow_html=True)
            st.markdown(f"<div style='margin-top:6px'>{row['description']}</div>", unsafe_allow_html=True)
            # recommend schemes
            schemes = recommend_schemes_for_text(row['text'], top_k=3)
            st.markdown("**Recommended Schemes:**")
            for _, s in schemes.iterrows():
                st.markdown(f"- {s['scheme_name']}  <span class='small-muted'>(score: {s['similarity']:.3f})</span>", unsafe_allow_html=True)
                all_result_rows.append({
                    "Query": query_text,
                    "NCO_Code": row['nco_code'],
                    "Job_Title": row['title'],
                    "Job_Description": row['description'],
                    "Job_Similarity": float(row['similarity']),
                    "Scheme_Name": s['scheme_name'],
                    "Scheme_Description": s.get('description',''),
                    "Scheme_Similarity": float(s['similarity'])
                })
            # speak option for each result
            speak_col1, speak_col2 = st.columns([1,5])
            with speak_col1:
                if st.button(f"ðŸ”Š Speak job {i}", key=f"tts_job_{i}"):
                    browser_tts(f"{row['title']}. {row['description']}", lang='en-IN')
            st.markdown("</div>", unsafe_allow_html=True)

        # Provide CSV download
        if all_result_rows:
            res_df = pd.DataFrame(all_result_rows)
            csv_bytes = res_df.to_csv(index=False).encode('utf-8')
            st.download_button("ðŸ“¥ Download search + scheme results", csv_bytes, "search_results.csv", "text/csv")

# -----------------------------
# Tab 2: Charts & Analytics
# -----------------------------
with tabs[1]:
    st.header("Analytics")
    st.write("Visual insights from the NCO dataset")
    c1, c2 = st.columns(2)
    with c1:
        # Sector distribution (use whole dataset)
        counts = df_jobs['sector'].value_counts().reset_index()
        counts.columns = ['sector','count']
        fig = px.pie(counts, names='sector', values='count', title="Jobs by Sector")
        st.plotly_chart(fig, use_container_width=True)
    with c2:
        # Top schemes by coverage (simple freq as example)
        # We compute embeddings similarity between each job and each scheme to estimate frequency (expensive) -> instead show sample of schemes list
        # Quick chart: top scheme names if present in df_schemes
        top_schemes = df_schemes['scheme_name'].value_counts().reset_index().rename(columns={'index':'scheme_name','scheme_name':'count'})
        if top_schemes.shape[0] == 0:
            st.info("No schemes data found.")
        else:
            fig2 = px.bar(top_schemes.head(12), x='scheme_name', y='count', title="Schemes (dataset count)")
            fig2.update_layout(xaxis={'tickangle':-45})
            st.plotly_chart(fig2, use_container_width=True)

    st.markdown("**Quick Metrics**")
    m1, m2, m3 = st.columns(3)
    m1.metric("Total NCO Jobs", df_jobs.shape[0])
    m2.metric("Total Schemes", df_schemes.shape[0])
    m3.metric("Embedding Dim", job_embeddings.shape[1] if job_embeddings is not None else "N/A")

# -----------------------------
# Tab 3: Chat & Voice
# -----------------------------
with tabs[2]:
    st.header("Chatbot (text + voice assist)")
    if 'chat_history' not in st.session_state:
        st.session_state['chat_history'] = []

    chat_col1, chat_col2 = st.columns([2,1])
    with chat_col1:
        user_msg = st.text_input("Ask about a job or scheme (you can paste voice text):", key='chat_input')
        if st.button("Send", key="send_btn"):
            if user_msg.strip():
                st.session_state.chat_history.append({"role":"user","text":user_msg.strip()})
                # Bot: find top 3 jobs and summarize
                jobs = semantic_search_jobs(user_msg.strip(), top_k=3)
                bot_reply_lines = []
                for _, r in jobs.iterrows():
                    bot_reply_lines.append(f"{r['nco_code']} â€” {r['title']}")
                if bot_reply_lines:
                    reply = "Top matches: " + "; ".join(bot_reply_lines)
                else:
                    reply = "Sorry, I couldn't find relevant occupations."
                st.session_state.chat_history.append({"role":"bot","text":reply})
                # Option: TTS speak reply automatically
                browser_tts(reply, lang='en-IN')
    with chat_col2:
        st.markdown("**Voice Input**")
        components.html(VOICE_COMPONENT, height=220)

    # Display chat history (latest at top)
    st.markdown("**Conversation**")
    for msg in st.session_state.chat_history[::-1]:
        if msg['role'] == 'user':
            st.markdown(f"<div style='background:#e8f0fe;padding:8px;border-radius:8px;margin-bottom:6px'><b>You:</b> {msg['text']}</div>", unsafe_allow_html=True)
        else:
            st.markdown(f"<div style='background:#fff7e6;padding:8px;border-radius:8px;margin-bottom:6px'><b>Bot:</b> {msg['text']}</div>", unsafe_allow_html=True)

# -----------------------------
# Footer / References
# -----------------------------
st.markdown("---")
st.markdown("**Data sources:** NCO 2015 (DGE/NCS). **Model:** paraphrase-multilingual-MiniLM-L12-v2 (sentence-transformers).")